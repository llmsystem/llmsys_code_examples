{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DEMO Code CUDA Acceleration\n",
        "\n",
        "We'll compare time differiential between `naive` vs `optimized` matrix multiplications on NxN matrices of size 512, 1024, 2048, 4096, 8192, and 16384.\n"
      ],
      "metadata": {
        "id": "jJj2BJGkmZfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installs"
      ],
      "metadata": {
        "id": "6JgH0miPnGwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5kAq1g-mHGP",
        "outputId": "b83b214d-2747-4b92-a0b1-cf6acbe04ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-a6eyk6dn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-a6eyk6dn\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "# Installing NVCC\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Py packages for visualization\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io"
      ],
      "metadata": {
        "id": "Sz8wGkiLjhuo"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mrzkp/llmsys_resources.git\n",
        "\n",
        "%cd llmsys_resources"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G8Bn75glw2L",
        "outputId": "5ad6deb3-ac57-4b9b-d068-add71880b47a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llmsys_resources' already exists and is not an empty directory.\n",
            "/content/llmsys_resources\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile"
      ],
      "metadata": {
        "id": "x7e0c52VntBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matmul_benchmark.cu -o matmul_benchmark -O3"
      ],
      "metadata": {
        "id": "fSxgBk9UnAdj"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize"
      ],
      "metadata": {
        "id": "fdMeXVGodmVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "output = !./matmul_benchmark\n",
        "data = \"\\n\".join([line for line in output if line.count(\",\") == 2])\n",
        "print(data)\n",
        "df = pd.read_csv(io.StringIO(data), names=['Size', 'Naive_ms', 'Tiled_ms'], header=None)\n",
        "\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(df['Size'], df['Naive_ms'], marker='o', label='Naive Kernel')\n",
        "plt.plot(df['Size'], df['Tiled_ms'], marker='s', label='Tiled Kernel (32x32)')\n",
        "\n",
        "plt.title('Naive vs. Tiled Performance', fontsize=14)\n",
        "plt.xlabel('Matrix Dimension (N)', fontsize=12)\n",
        "plt.ylabel('Exec Time (ms)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfPQ_QlooHHk",
        "outputId": "2daff797-34d1-442c-c732-5943041d4596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive,Tiled\n",
            "512,0.886624,0.748896\n",
            "1024,6.73814,5.32704\n",
            "2048,50.5786,38.2878\n",
            "4096,207.833,142.135\n",
            "8192,1695.45,1132.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample performance comparison between Naive vs. Tiled\n",
        "\n",
        "| Matrix Size ($N$) | Naive Time (ms) | Tiled Time (ms) | Speedup Ratio |\n",
        "| :--- | :---: | :---: | :---: |\n",
        "| **512** | 0.887 | 0.733 | 1.21x |\n",
        "| **1,024** | 6.737 | 5.329 | 1.25x |\n",
        "| **2,048** | 53.608 | 42.004 | 1.28x |\n",
        "| **4,096** | 218.481 | 148.042 | 1.48x |\n",
        "| **8,192** | 1,807.72 | 1,181.44 | 1.53x |\n",
        "| **16,384** | 16,326.1 | 10,052.9 | 1.62x |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0oc_z50-ZceE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Questions and Explanations\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Why does the speedup increase as N increases?\n",
        "As N increases, the number of data grows by a factor of N^2, hence, requiring exponentially more global memory reads.\n",
        "\n",
        "Furthemore, depending on the GPU architecture, there is a L2 cache.\n",
        "\n",
        "In our case, T4 GPU has a 6 MB L2 cache.\n",
        "\n",
        "We can solve for the maximal N that can fit in the L2 cache (assuming 4 byte floating point numbers), via: 6 MB = N x N x 4 Bytes, or N ~= 1224. Since memory bandwidth from L2 to registers is much faster than main memory to registers, Naive performs well comparatively to the Optimized.\n",
        "\n",
        "---\n",
        "\n",
        "### How would we get better speedup?\n",
        "\n",
        "Similar to tiling, there is something called `register tiling`. This is, essentially, another level of tiling where we place our data at the register level instead of just using shared memory. It's like a `cache for the cache`.\n",
        "\n",
        "Other techinques include double (or even triple) buffering in libraies such as `cuBLAS`. These are much more advanced and aren't necessary for your homework assignments (but you are free to do your own research and try to implement them)."
      ],
      "metadata": {
        "id": "EHXONXQhGIox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-RWiNx-CG27M"
      }
    }
  ]
}